{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import shutil\n",
    "import matplotlib.pyplot\n",
    "import pickle\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.models import Sequential\n",
    "from keras import optimizers\n",
    "from keras.applications import VGG16\n",
    "from PIL import Image\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#create strings for directory access\n",
    "baseDirectory = r'C:\\Users\\Administrator\\Desktop\\Personal-Projects-Blood-Type-Prediction\\Dataset'\n",
    "\n",
    "\n",
    "trainDirectory = r'C:\\Users\\Administrator\\Desktop\\Personal-Projects-Blood-Type-Prediction\\Dataset\\TRAIN'\n",
    "smallTrainDirectory = r'C:\\Users\\Administrator\\Desktop\\Personal-Projects-Blood-Type-Prediction\\Dataset\\SMALLTRAIN'\n",
    "finalTrainDirectory = r'C:\\Users\\Administrator\\Desktop\\Personal-Projects-Blood-Type-Prediction\\Dataset\\FINALTRAIN'\n",
    "\n",
    "\n",
    "testDirectory = r'C:\\Users\\Administrator\\Desktop\\Personal-Projects-Blood-Type-Prediction\\Dataset\\TEST'\n",
    "smallTestDirectory = r'C:\\Users\\Administrator\\Desktop\\Personal-Projects-Blood-Type-Prediction\\Dataset\\SMALLTEST'\n",
    "\n",
    "\n",
    "subdirectoriesList = [ 'EOSINOPHIL', 'LYMPHOCYTE', 'MONOCYTE', 'NEUTROPHIL' ]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#make small train directories because the learning time is too long\n",
    "\n",
    "# os.chdir( baseDirectory )\n",
    "# os.mkdir( 'SMALLTRAIN' )\n",
    "\n",
    "# os.chdir( smallTrainDirectory )\n",
    "# os.mkdir( 'EOSINOPHIL' )\n",
    "# os.mkdir( 'LYMPHOCYTE' )\n",
    "# os.mkdir( 'MONOCYTE' )\n",
    "# os.mkdir( 'NEUTROPHIL' )\n",
    "\n",
    "\n",
    "# os.chdir( trainDirectory )\n",
    "# for subdirectory in subdirectoriesList:\n",
    "#     os.chdir( trainDirectory + '\\\\' + subdirectory )\n",
    "#     fileNames = os.listdir()\n",
    "    \n",
    "#     for fileNameIndex in range( 600 ):\n",
    "#         fileName = fileNames[ fileNameIndex ]\n",
    "#         shutil.copy( fileName, smallTrainDirectory + '\\\\' + subdirectory )\n",
    "        \n",
    "    \n",
    "    \n",
    "\n",
    "#make small test directory because the learning time is too long\n",
    "# os.chdir( baseDirectory )\n",
    "# os.mkdir( 'SMALLTEST' )\n",
    "\n",
    "# os.chdir( smallTestDirectory )\n",
    "# os.mkdir( 'EOSINOPHIL' )\n",
    "# os.mkdir( 'LYMPHOCYTE' )\n",
    "# os.mkdir( 'MONOCYTE' )\n",
    "# os.mkdir( 'NEUTROPHIL' )\n",
    "\n",
    "\n",
    "# os.chdir( testDirectory )\n",
    "# for subdirectory in subdirectoriesList:\n",
    "#     os.chdir( testDirectory + '\\\\' + subdirectory )\n",
    "#     fileNames = os.listdir()\n",
    "    \n",
    "#     for fileNameIndex in range( 250 ):\n",
    "#         fileName = fileNames[ fileNameIndex ]\n",
    "#         shutil.copy( fileName, smallTestDirectory + '\\\\' + subdirectory )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2400 images belonging to 4 classes.\n",
      "Found 9957 images belonging to 4 classes.\n",
      "Found 2487 images belonging to 4 classes.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#create generators for images\n",
    "finalTrainGenerator = ImageDataGenerator(rescale = (1/255))\n",
    "\n",
    "testGenerator = ImageDataGenerator(rescale = (1/255))\n",
    "\n",
    "trainGenerator = ImageDataGenerator(rescale = (1/255))\n",
    "\n",
    "\n",
    "\n",
    "#create directory iterators from generators\n",
    "trainDirectoryIterator = trainGenerator.flow_from_directory(directory = smallTrainDirectory,\n",
    "                                                            target_size = (128, 128),\n",
    "                                                            class_mode = 'categorical',\n",
    "                                                            batch_size = 128)\n",
    "\n",
    "\n",
    "finalTrainDirectoryIterator = finalTrainGenerator.flow_from_directory(directory = finalTrainDirectory,\n",
    "                                                                      target_size = (128, 128),\n",
    "                                                                      class_mode = 'categorical',\n",
    "                                                                      batch_size = 128)\n",
    "\n",
    "\n",
    "testDirectoryIterator = testGenerator.flow_from_directory(directory = testDirectory,\n",
    "                                                          target_size = (128, 128),\n",
    "                                                          class_mode = 'categorical',\n",
    "                                                          batch_size = 128)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "3/3 [==============================] - 9s 3s/step - loss: 1.4675 - acc: 0.2474 - val_loss: 1.3862 - val_acc: 0.2525\n",
      "Epoch 2/3\n",
      "3/3 [==============================] - 8s 3s/step - loss: 1.3807 - acc: 0.2812 - val_loss: 1.3804 - val_acc: 0.2939\n",
      "Epoch 3/3\n",
      "3/3 [==============================] - 8s 3s/step - loss: 1.3850 - acc: 0.2656 - val_loss: 1.3737 - val_acc: 0.2996\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#create the convolutional base \n",
    "convolutionalBase = VGG16( weights = 'imagenet',\n",
    "                           include_top = False,\n",
    "                           input_shape = ( 128, 128, 3 ) )\n",
    "\n",
    "\n",
    "#freeze the convolutional base\n",
    "convolutionalBase.trainable = False \n",
    "\n",
    "\n",
    "#create the sequential model with the VGG16 convolutional base\n",
    "sequentialModel = Sequential()\n",
    "sequentialModel.add( convolutionalBase )\n",
    "sequentialModel.add( Flatten() )\n",
    "sequentialModel.add( Dropout( 0.3 ) )\n",
    "sequentialModel.add( Dense( 256, activation = 'relu' ) )\n",
    "sequentialModel.add( Dense( 4, activation = 'sigmoid' ) )\n",
    "\n",
    "\n",
    "#compile the model\n",
    "sequentialModel.compile( optimizer = optimizers.RMSprop( lr = 1e-4 ),\n",
    "                       loss = 'categorical_crossentropy',\n",
    "                       metrics = [ 'acc' ] )\n",
    "\n",
    "\n",
    "#train the model\n",
    "sequentialModelHistory = sequentialModel.fit_generator( generator = finalTrainDirectoryIterator,\n",
    "                                                         steps_per_epoch = 78,\n",
    "                                                         epochs = 60,\n",
    "                                                         verbose = True,\n",
    "                                                         validation_data = testDirectoryIterator,\n",
    "                                                         validation_steps = 20 )\n",
    "\n",
    "#save the model\n",
    "sequentialModel.save( 'BloodTypeClassifierUsingVGG16Base.h5' )\n",
    "\n",
    "#retrieve the training history\n",
    "sequentialModelHistory = sequentialModelHistory.history\n",
    "\n",
    "#save the training history to file\n",
    "os.chdir( baseDirectory )\n",
    "with open('trainHistoryDictionary.obj', 'wb') as fileToPickle:\n",
    "        pickle.dump(sequentialModelHistory, fileToPickle)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'val_loss': [1.386176065023903, 1.3803784477217014, 1.3736656622854064], 'acc': [0.24739583333333334, 0.28125, 0.265625], 'loss': [1.4674618244171143, 1.3806888659795125, 1.3850034077962239], 'val_acc': [0.2525130679114161, 0.2939284278366716, 0.2995577002199577]}\n"
     ]
    }
   ],
   "source": [
    "# with open( 'trainHistoryDictionary.obj', 'rb' ) as inputHistory:\n",
    "#           trainHistory = pickle.load(inputHistory)\n",
    "        \n",
    "   "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
